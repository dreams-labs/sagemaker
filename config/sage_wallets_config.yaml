#SageMaker Config

training_data: #SageMaker
    local_s3_root: ../  # where s3_uploads and s3_downloads exist
    training_data_directory: dda_945_filters_bal  # where to load local csvs from
    # local_directory: dda_930_concat_model  # where to store local artifacts
    # upload_directory: dda-930-vt-perf  # new S3 folder name in bucket training_data_processed

    # local_directory: dda_945_filters_bal_s  # where to store local artifacts
    # upload_directory: dda-945-filt-bal-s  # new S3 folder name in bucket training_data_processed
    local_directory: dda_947_x_in_cont_v7  # where to store local artifacts
    upload_directory: dda-947-x-in-cont  # new S3 folder name in bucket training_data_processed


    dataset: dev  # Set to prod or dev; determines whether to query core or dev dataset tables

    concatenate_offsets: True  # whether to model each offset individually or concat them together
    date_0: '200127' # the date that all offsets will be numbered relative to
    epoch_shifts: [  # a model will be constructed for each of these shifts from the base offsets
        # 0,
        60,
        # 120
    ]

    train_offsets: [
        # '200127',
        # '200226',
        # '200327',
        # '200426',
        # '200526',
        # '200625',
        # '200725',
        # '200824',
        # '200923',
        # '201023',
        # '201122',
        # '201222',
        # '210121',
        # '210220',
        # '210322',
        # '210421',
        # '210521',
        # '210620',
        # '210720',
        # '210819',
        # '210918',
        # '211018',
        # '211117',
        # '211217',
        # '220116',
        # '220215',
        # '220317',
        # '220416',
        # '220516',
        # '220615',
        # '220715',
        # '220814',
        # '220913',
        # '221013',
        # '221112',
        # '221212',
        # '230111',
        # '230210',
        # '230312',
        # '230411',
        # '230511',
        # '230610',
        # '230710',
        # # '230809',
        # '230908',
        # # '231008',
        # '231107',
        # # '231207',
        '240106',
        # '240205',
        '240306',
        # '240405',
        # '240505',
        # '240604',
        # '240704',
        # '240803',
        # '240902',
        # '241002',
        # '241101',
        # '241201',
        # '241231',
        # '250130',
        # '250301',
        # '250331',
        # '250430',
        # '250530',
    ]
    eval_offsets: [
        '230809',
        '230908',
        '231008',
        '231107',
        '231207',
        '240106',
        '240205',
        '240306',
        '240405',
        # '240505',
        # '240604',
        # '240704',
        # '240803',
    ]
    test_offsets: [
        '230809',
        '230908',
        '231008',
        '231107',
        '231207',
        '240106',
        '240205',
        '240306',
        '240405',
    ]
    val_offsets: [  # val data is 1 month later than these modeling_period_start dates
        '240405',
        '240505',
        '240604',
        '240704',
        '240803',
        '240902',
    ]

preprocessing: #SageMaker
    fill_na:
        coin_trends: -1
        mktcap: -1
        performance: 0
        scenario|ideal: max
        scenario|worst: min
        scenario|net_perf: mean
        transfers: -1
        timing: 0
        balance: 0
        macro: -1

workflow:
    override_existing_models: True  # whether to train models for a date_suffix if one already exists

aws: #SageMaker
    training_bucket: wallet-training-data
    script_model_bucket: wallet-script-models
    preprocessed_directory: training-data-preprocessed
    concatenated_directory: training-data-concatenated
    temporal_cv_directory: training-data-temporal-cvs
    modeler_arn: arn:aws:iam::891377123484:role/sagemaker_runner

n_threads: #SageMaker
    upload_all_training_data: 4 # how many uploads to perform concurrently
    train_all_models: 4 # how many models to train concurrently
    predict_datasets: 4 # whether to score 'test' and 'val' sets concurrently
    predict_all_models: 4 # how many test/val pairs to score concurrently
    evaluate_all_models: 4 # how many test/val pairs to score concurrently